{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "raw",
    "id": "YZ0jiceziO12"
   },
   "source": [
    "\"\"\"\n",
    "   Copyright 2019-2020 Boris Shminke\n",
    "\n",
    "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "   you may not use this file except in compliance with the License.\n",
    "   You may obtain a copy of the License at\n",
    "\n",
    "       http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "   Unless required by applicable law or agreed to in writing, software\n",
    "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "   See the License for the specific language governing permissions and\n",
    "   limitations under the License.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7927,
     "status": "ok",
     "timestamp": 1586193013830,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "ggqDc_vtiR4y",
    "outputId": "4a1ec1e9-9978-4466-e439-6eb49e9a0cdf"
   },
   "outputs": [],
   "source": [
    "# use this if you've just uploaded this notebook to Google Colaboratory\n",
    "# don't forget to restart your runtime after the package installation\n",
    "# better use a GPU runtime (TPU ones are not supported by the package yet)\n",
    "!pip install neural-semigroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "16fm12yGiO13"
   },
   "source": [
    "If you have a Cayley database, you can build a machine learning model for such a task:\n",
    "\n",
    "Given a partially filled Cayley table of a semigroup, restore the full one.\n",
    "\n",
    "It should be mentioned that a partially filled table sometimes can be filled in several ways to a full associative table. We will consider all such solutions as equally valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7H75-2WiO14"
   },
   "source": [
    "In `neural-semigroups` package we use `torch` for building deep learning models.\n",
    "\n",
    "First of all, we need to get some training and validation data.\n",
    "In this example, we take semigroups of 5 items, and hold 100 Cayley tables (each representing a different class of equivalent semigrous) as our training data, and another 100 tables as validation.\n",
    "This is a rough 10/90 split of all tables of 5 elements available (there are 1160 of them up to equivalence).\n",
    "\n",
    "Here we construct `DataLoaders` for `torch` which will feed a training pipeline with 512 tables at a time.\n",
    "This number (batch size) can be changed for fine-tuning the model's quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17386,
     "status": "ok",
     "timestamp": 1586193043006,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "pcBK9-zViO15",
    "outputId": "e4ac5e11-f75b-4c4a-a6ee-192193e8fea1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading /root/neural-semigroups-data/tmp/smallsemi-0.6.12.tar.bz2: 20529kB [00:00, 44100.39kB/s]                           \n",
      "augmenting by equivalent tables: 100%|██████████| 100/100 [00:00<00:00, 166.22it/s]\n",
      "generating train cubes: 100%|██████████| 14750/14750 [00:00<00:00, 57530.86it/s]\n",
      "generating validation cubes: 100%|██████████| 100/100 [00:00<00:00, 23571.45it/s]\n",
      "generating test cubes: 100%|██████████| 960/960 [00:00<00:00, 41142.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from neural_semigroups.training_helpers import get_loaders\n",
    "\n",
    "cardinality = 5\n",
    "data_loaders = get_loaders(\n",
    "    cardinality=cardinality,\n",
    "    batch_size=512,\n",
    "    train_size=100,\n",
    "    validation_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zw8TTr7_iO19"
   },
   "source": [
    "Note that for a training set we:\n",
    "* take 100 representatives of different equivalence classes\n",
    "* augment data by adding all equivalent tables\n",
    "* as a result, we will train on 16100 tables from 100 classes of equivalence\n",
    "\n",
    "For validation we simply use 100 tables from different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Qyl3eAOiO1-"
   },
   "source": [
    "We model each input Cayley table as a three index tensor $a_{ijk}$ such that\n",
    "\n",
    "$a_{ijk}=P\\left\\{e_ie_j=e_k\\right\\}$\n",
    "\n",
    "where $e_i$ are elements of a semigroup.\n",
    "\n",
    "In our training data all $a_{ijk}$ are either zeros or ones, so probability distributions involved are degenerate.\n",
    "\n",
    "When we need to hide a cell with indices $i,j$ from an original Cayley table we set\n",
    "\n",
    "$a_{ijk}=\\dfrac1n$\n",
    "\n",
    "where $n$ is the semigroup's cardinality. Thus we set a probability distribution of the multiplication result $e_ie_j$ to discrete uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HJqD5qlziO1-"
   },
   "source": [
    "We choose a simple denoising autoencoder as an architecture for our neural network. It simply gets an input tensor of zeros and ones, hides 50% of input cells in a manner described earlier, and applies a linear transformation into a higher dimension ($n^5$ which is contrary to a common idea of autoencoders) with a simple `ReLU` non-linearity. Then another linear transformation to the same dimension with `ReLU` is applied, and then the last one to return back to the original $n^3$ dimension. We also apply batch normalization here. See the package code for the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "id": "aKqRTYjXiO1_"
   },
   "outputs": [],
   "source": [
    "from neural_semigroups import MagmaDAE\n",
    "from neural_semigroups.constants import CURRENT_DEVICE\n",
    "\n",
    "dae = MagmaDAE(\n",
    "    cardinality=cardinality,\n",
    "    hidden_dims=[\n",
    "        cardinality ** 5,\n",
    "        cardinality ** 5\n",
    "    ],\n",
    "    corruption_rate=0.5\n",
    ").to(CURRENT_DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_XyKiokHSMO"
   },
   "source": [
    "In total, our model has ca 20 million  parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1047,
     "status": "ok",
     "timestamp": 1586193342243,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "3vKeetXSiO2C",
    "outputId": "f8f31e12-0e85-425a-f849-d0ebe41b38e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20341000"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": null
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in dae.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V-wshINgiO2F"
   },
   "source": [
    "During the training process we try to minimize a special [associator loss](https://neural-semigroups.readthedocs.io/en/latest/package-documentation.html#associator-loss) on the output of the DAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "id": "8-Hdb9iaiO2G"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from neural_semigroups import AssociatorLoss\n",
    "\n",
    "def loss(prediction: Tensor, target: Tensor) -> Tensor:\n",
    "    return AssociatorLoss()(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0OgutrW1iO2N"
   },
   "source": [
    "Now it's time to run a pipeline! Here you can tune the learning schedule for better results.\n",
    "\n",
    "You can construct your own pipeline if you don't want to import one provided by the package.\n",
    "\n",
    "In the next three cells we will run `tensorboard` to show training/validation curves during training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pkill tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 189134,
     "status": "ok",
     "timestamp": 1586194222531,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "VfreVgnniO2W",
    "outputId": "36a8c815-81bf-49ac-d761-02649ac9779b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 1s, sys: 54.5 s, total: 2min 56s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "from neural_semigroups.training_helpers import learning_pipeline\n",
    "\n",
    "params = {\"learning_rate\": 0.001, \"epochs\": 1000}\n",
    "learning_pipeline(params, cardinality, dae, loss, data_loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we restore the best saved model from a checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dae.load_state_dict(\n",
    "    torch.load(os.path.join(\"checkpoints\", os.listdir(\"checkpoints\")[0]))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K0ikjKaIiO2Y"
   },
   "source": [
    "And here is the report of results. It seems to be quite impressive. For it we took random 1000 Cayley tables from 5 elements (for different equivalent classes as always) and constructed 'puzzles' from it.\n",
    "\n",
    "Level of difficulty for a puzzle is a number of hidden cells. A puzzle is considered to be solved if the model returns a full associative table.\n",
    "\n",
    "We see that the model generalizes well (it was trained only on one tenth of all equivalence classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30223,
     "status": "ok",
     "timestamp": 1586194305892,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "xPGuNTipiO2Z",
    "outputId": "6bee8dfe-b81e-4c84-9984-4e35c8eba012"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating and solving puzzles: 100%|██████████| 1000/1000 [00:29<00:00, 34.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>puzzles</th>\n",
       "      <th>solved</th>\n",
       "      <th>(%)</th>\n",
       "      <th>hidden cells</th>\n",
       "      <th>guessed</th>\n",
       "      <th>in %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>970</td>\n",
       "      <td>97</td>\n",
       "      <td>1000</td>\n",
       "      <td>970</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>933</td>\n",
       "      <td>93</td>\n",
       "      <td>2000</td>\n",
       "      <td>1927</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>922</td>\n",
       "      <td>92</td>\n",
       "      <td>3000</td>\n",
       "      <td>2902</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>894</td>\n",
       "      <td>89</td>\n",
       "      <td>4000</td>\n",
       "      <td>3855</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>878</td>\n",
       "      <td>87</td>\n",
       "      <td>5000</td>\n",
       "      <td>4798</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>849</td>\n",
       "      <td>84</td>\n",
       "      <td>6000</td>\n",
       "      <td>5734</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>836</td>\n",
       "      <td>83</td>\n",
       "      <td>7000</td>\n",
       "      <td>6691</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>820</td>\n",
       "      <td>82</td>\n",
       "      <td>8000</td>\n",
       "      <td>7658</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>798</td>\n",
       "      <td>79</td>\n",
       "      <td>9000</td>\n",
       "      <td>8509</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000</td>\n",
       "      <td>779</td>\n",
       "      <td>77</td>\n",
       "      <td>10000</td>\n",
       "      <td>9430</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1000</td>\n",
       "      <td>767</td>\n",
       "      <td>76</td>\n",
       "      <td>11000</td>\n",
       "      <td>10335</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1000</td>\n",
       "      <td>764</td>\n",
       "      <td>76</td>\n",
       "      <td>12000</td>\n",
       "      <td>11310</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       puzzles  solved  (%)  hidden cells  guessed  in %\n",
       "level                                                   \n",
       "1         1000     970   97          1000      970    97\n",
       "2         1000     933   93          2000     1927    96\n",
       "3         1000     922   92          3000     2902    96\n",
       "4         1000     894   89          4000     3855    96\n",
       "5         1000     878   87          5000     4798    95\n",
       "6         1000     849   84          6000     5734    95\n",
       "7         1000     836   83          7000     6691    95\n",
       "8         1000     820   82          8000     7658    95\n",
       "9         1000     798   79          9000     8509    94\n",
       "10        1000     779   77         10000     9430    94\n",
       "11        1000     767   76         11000    10335    93\n",
       "12        1000     764   76         12000    11310    94"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": null
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neural_semigroups.utils import print_report\n",
    "from neural_semigroups import CayleyDatabase\n",
    "\n",
    "cayley_db = CayleyDatabase(cardinality)\n",
    "cayley_db.load_model(f\"semigroups.{cardinality}.model\")\n",
    "print_report(cayley_db.testing_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SvQhUdn-iO2b"
   },
   "source": [
    "Now let's see how it works on several example puzzles. Let's take one of the real tables from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 581,
     "status": "ok",
     "timestamp": 1586103950061,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "2OWsBRLziO2c",
    "outputId": "0bc958d1-df7d-44bf-e24e-985fc5df3aa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 1],\n",
       "       [0, 1, 2, 1, 1],\n",
       "       [0, 1, 1, 3, 1],\n",
       "       [0, 1, 1, 1, 4]])"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": null
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cayley_db.database[1100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kOjWjAO-iO2e"
   },
   "source": [
    "Then we can fill it with `-1` in some cells, creating a puzzle and giving it to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "id": "YCGHojbUiO2f"
   },
   "outputs": [],
   "source": [
    "guess, proba = cayley_db.fill_in_with_model([\n",
    "  [-1, 0, 0, 0, -1],\n",
    "  [0, -1, 1, 1, -1],\n",
    "  [0, 1, -1, 1, -1],\n",
    "  [0, 1, 1, -1, -1],\n",
    "  [0, 1, 1, 1, -1]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "db3Ibj4MiO2h"
   },
   "source": [
    "The model found not the same table as the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 603,
     "status": "ok",
     "timestamp": 1586104106228,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "5nFODtvhiO2h",
    "outputId": "9ab2c9d6-bb32-4de5-eb14-665bbcda5233"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": null
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rrN_VNsRiO2k"
   },
   "source": [
    "But it's still a possible completion since it's associative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 632,
     "status": "ok",
     "timestamp": 1586104107490,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "JUM5bp22iO2k",
    "outputId": "226e7af8-96f2-4db4-e296-22fdab1a831b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": null
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neural_semigroups import Magma\n",
    "\n",
    "Magma(guess).is_associative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kHYgB7DziO2m"
   },
   "source": [
    "The model returns also it's probabilities of guess. They can be examined in cases when the model err."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1586104119925,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "kZjuj6nCiO2n",
    "outputId": "00c94fe1-9c5d-4578-a77e-0d307c13f5c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[9.99333322e-01, 1.76233807e-04, 1.69513907e-04, 1.57693794e-04,\n",
       "         1.63226068e-04],\n",
       "        [9.99996006e-01, 9.99999997e-07, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [9.99996006e-01, 9.99999997e-07, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [9.99996006e-01, 9.99999997e-07, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [9.97627914e-01, 5.14849497e-04, 5.12598548e-04, 4.79601236e-04,\n",
       "         8.65101989e-04]],\n",
       "\n",
       "       [[9.99996006e-01, 9.99999997e-07, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [8.40733628e-05, 9.99669909e-01, 8.22106012e-05, 7.92966748e-05,\n",
       "         8.45939721e-05],\n",
       "        [9.99999997e-07, 9.99996006e-01, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [9.99999997e-07, 9.99996006e-01, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [3.12888267e-04, 9.98497725e-01, 3.14911304e-04, 3.19190294e-04,\n",
       "         5.55210223e-04]],\n",
       "\n",
       "       [[9.99996006e-01, 9.99999997e-07, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [9.99999997e-07, 9.99996006e-01, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [1.60055992e-04, 9.88433182e-01, 1.05470326e-02, 2.13558349e-04,\n",
       "         6.46344037e-04],\n",
       "        [9.99999997e-07, 9.99996006e-01, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [1.05975814e-04, 9.87890959e-01, 4.65394201e-04, 1.86237041e-04,\n",
       "         1.13514215e-02]],\n",
       "\n",
       "       [[9.99996006e-01, 9.99999997e-07, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [9.99999997e-07, 9.99996006e-01, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [9.99999997e-07, 9.99996006e-01, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [1.34608999e-04, 9.88581717e-01, 1.74623623e-04, 1.09779211e-02,\n",
       "         1.31208930e-04],\n",
       "        [3.78465513e-04, 9.82654989e-01, 4.41268116e-04, 1.60866464e-03,\n",
       "         1.49165587e-02]],\n",
       "\n",
       "       [[9.99996006e-01, 9.99999997e-07, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [9.99999997e-07, 9.99996006e-01, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [9.99999997e-07, 9.99996006e-01, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [9.99999997e-07, 9.99996006e-01, 9.99999997e-07, 9.99999997e-07,\n",
       "         9.99999997e-07],\n",
       "        [1.92296889e-03, 6.33532822e-01, 1.95470941e-03, 2.07230239e-03,\n",
       "         3.60517263e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": null
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "id": "d6xNjdbjiO2p"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of Copy of train_a_model.ipynb",
   "provenance": {
    "file_id": [
     "https://github.com/inpefess/neural-semigroups/blob/master/examples/train_a_model.ipynb",
     "timestamp",
     1586104136544
    ]
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "name": "train_a_model.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
